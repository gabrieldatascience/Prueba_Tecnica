{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a id='top'></a>\n",
        "# NLP - Modelo Pregunta-Respuesta\n",
        "###Dataset: https://rajpurkar.github.io/SQuAD-explorer/\n"
      ],
      "metadata": {
        "id": "NcDc1aQAIg54"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSLNvgZCIgdK"
      },
      "outputs": [],
      "source": [
        "import wikipedia as wiki\n",
        "\n",
        "k = 5\n",
        "question = \"What are the tourist hotspots in Mexico?\"\n",
        "\n",
        "results = wiki.search(question, results=k)\n",
        "print('Question:', question)\n",
        "print('Pages:  ', results)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "UY6aM01qImfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar el módulo os para manipulación de archivos y directorios\n",
        "import os\n",
        "\n",
        "# Listar los datos disponibles\n",
        "# Recorre todos los directorios y archivos dentro de '/kaggle/input'\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        # Imprimir la ruta completa de cada archivo encontrado\n",
        "        print(os.path.join(dirname, filename))\n"
      ],
      "metadata": {
        "id": "oHq-5Mr_IqYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def squad_json_to_dataframe(file_path, record_path=['data', 'paragraphs', 'qas', 'answers']):\n",
        "    \"\"\"\n",
        "    file_path: ruta al archivo JSON de SQuAD.\n",
        "    record_path: ruta hasta el nivel más profundo en el archivo JSON, el valor predeterminado es\n",
        "    ['data', 'paragraphs', 'qas', 'answers']\n",
        "    \"\"\"\n",
        "    # Cargar el archivo JSON\n",
        "    archivo = json.loads(open(file_path).read())\n",
        "\n",
        "    # Analizar los diferentes niveles del archivo JSON\n",
        "    js = pd.json_normalize(archivo, record_path)\n",
        "    m = pd.json_normalize(archivo, record_path[:-1])\n",
        "    r = pd.json_normalize(archivo, record_path[:-2])\n",
        "\n",
        "    # Combinar todo en un solo dataframe\n",
        "    idx = np.repeat(r['context'].values, r.qas.str.len())\n",
        "    m['context'] = idx\n",
        "    data = m[['id', 'question', 'context', 'answers']].set_index('id').reset_index()\n",
        "    data['c_id'] = data['context'].factorize()[0]\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "mWXp_u_hItSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar los datos\n",
        "file_path = '/kaggle/input/stanford-question-answering-dataset/train-v1.1.json'\n",
        "data = squad_json_to_dataframe(file_path)\n",
        "data"
      ],
      "metadata": {
        "id": "UwiGVs9aIyNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cuantos datos son unicos?\n",
        "data['c_id'].unique().size"
      ],
      "metadata": {
        "id": "8TJ7chC2I5Ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = data[['context', 'c_id']].drop_duplicates().reset_index(drop=True)\n",
        "documents"
      ],
      "metadata": {
        "id": "rcPkJJ0jI5_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Definir la configuración para TF-IDF\n",
        "tfidf_configs = {\n",
        "    'lowercase': True,  # Convertir todo a minúsculas\n",
        "    'analyzer': 'word',  # Analizar a nivel de palabras\n",
        "    'stop_words': 'english',  # Remover palabras comunes en inglés\n",
        "    'binary': True,  # Usar representación binaria para contar términos\n",
        "    'max_df': 0.9,  # Descartar palabras que aparecen en más del 90% de los documentos\n",
        "    'max_features': 10_000  # Limitar el número máximo de características a 10,000\n",
        "}\n",
        "\n",
        "# Definir el número de documentos a recuperar\n",
        "retriever_configs = {\n",
        "    'n_neighbors': 10,  # Número de vecinos más cercanos a buscar\n",
        "    'metric': 'cosine'  # Métrica de similitud a utilizar (coseno en este caso)\n",
        "}\n",
        "\n",
        "# Definir nuestra pipeline\n",
        "embedding = TfidfVectorizer(**tfidf_configs)  # Instanciar el vectorizador TF-IDF con la configuración dada\n",
        "retriever = NearestNeighbors(**retriever_configs)  # Instanciar el algoritmo de búsqueda de vecinos más cercanos con la configuración dada"
      ],
      "metadata": {
        "id": "tvOMcHUDI9X9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos a entrenar el modelo para recuperar el identificador del documento 'c_id':\n",
        "X = embedding.fit_transform(documents['context'])\n",
        "retriever.fit(X, documents['c_id'])"
      ],
      "metadata": {
        "id": "xCDqOdqZJCUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_text(vectorizer, text):\n",
        "    '''\n",
        "    Print the text and the vector[TF-IDF]\n",
        "    vectorizer: sklearn.vectorizer\n",
        "    text: str\n",
        "    '''\n",
        "    print('Text:', text)\n",
        "    vector = vectorizer.transform([text])\n",
        "    vector = vectorizer.inverse_transform(vector)\n",
        "    print('Vect:', vector)"
      ],
      "metadata": {
        "id": "66-3rsWsJE_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vectorizar la pregunta\n",
        "transform_text(embedding, question)"
      ],
      "metadata": {
        "id": "XJB5-e_pJHxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = embedding.transform([question])  # Transformar la pregunta en una representación numérica usando el vectorizador TF-IDF\n",
        "c_id = retriever.kneighbors(X, return_distance=False)[0][0]  # Obtener el índice del documento más similar a la pregunta\n",
        "selected = documents.iloc[c_id]['context']  # Obtener el contexto del documento seleccionado\n",
        "\n",
        "# Vectorizar el documento seleccionado\n",
        "transform_text(embedding, selected)"
      ],
      "metadata": {
        "id": "nZpD5EqPJKQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Predecir un documento para cada pregunta\n",
        "X = embedding.transform(data['question'])  # Transformar las preguntas en representaciones numéricas utilizando el vectorizador TF-IDF\n",
        "y_test = data['c_id']  # Obtener los identificadores de los documentos de prueba\n",
        "y_pred = retriever.kneighbors(X, return_distance=False)  # Realizar predicciones de los documentos más similares a las preguntas"
      ],
      "metadata": {
        "id": "CK-nqgqxJM02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar los documentos principales predichos para cada pregunta:\n",
        "y_pred"
      ],
      "metadata": {
        "id": "70ycqm6IJPUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def top_accuracy(y_true, y_pred) -> float:\n",
        "#Calcula la precisión superior (top accuracy) de las predicciones.\n",
        "\n",
        "#y_true: Lista de valores verdaderos de los documentos.\n",
        "#y_pred: Lista de listas con los documentos predichos para cada pregunta.\n",
        "\n",
        "#Retorna el valor de precisión superior.\n",
        "    right, count = 0, 0\n",
        "    for i, y_t in enumerate(y_true):\n",
        "        count += 1\n",
        "        if y_t in y_pred[i]:\n",
        "            right += 1\n",
        "    return right / count if count > 0 else 0\n"
      ],
      "metadata": {
        "id": "Zk2QTdw6JRqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular y mostrar la precisión superior, cantidad de predicciones correctas y total de predicciones\n",
        "acc = top_accuracy(y_test, y_pred)\n",
        "print('Accuracy:', f'{acc:.4f}')\n",
        "print('Quantity:', int(acc*len(y_pred)), 'from', len(y_pred))"
      ],
      "metadata": {
        "id": "JkAJ1WjmJUL-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}